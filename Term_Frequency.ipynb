{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e375dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TERM FREQUENCY (TF) TABLE ====================\n",
      "\n",
      "           d1  d2  d3  d4  d5  d6  d7  d8  d9  d10\n",
      "Term                                              \n",
      "antony      1   1   0   0   0   1   0   0   0    0\n",
      "brutus      1   1   0   1   0   0   0   0   0    0\n",
      "caeser      1   1   0   1   1   1   0   0   0    0\n",
      "calpurnia   0   1   0   0   0   0   0   0   0    0\n",
      "cleopatra   1   0   0   0   0   0   0   0   0    0\n",
      "mercy       1   0   1   1   1   1   0   0   0    0\n",
      "worse       1   0   1   1   1   0   0   0   0    0\n",
      "angel       0   0   0   0   0   0   1   1   1    0\n",
      "fool        0   0   0   0   0   0   1   1   1    1\n",
      "fear        0   0   0   0   0   0   1   1   0    1\n",
      "in          0   0   0   0   0   0   1   1   1    1\n",
      "rush        0   0   0   0   0   0   1   1   1    1\n",
      "to          0   0   0   0   0   0   1   1   1    1\n",
      "tread       0   0   0   0   0   0   1   1   1    1\n",
      "where       0   0   0   0   0   0   1   1   1    1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# ============================\n",
    "# Improve Pandas display\n",
    "# ============================\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# ============================\n",
    "# 1. Read positional_index.txt\n",
    "# ============================\n",
    "\n",
    "positional_index_file = \"positional_index.txt\"\n",
    "\n",
    "terms = {}\n",
    "current_term = None\n",
    "\n",
    "with open(positional_index_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        # Detect term line \"< antony\"\n",
    "        if line.startswith(\"< \") and len(line.split()) == 2:\n",
    "            current_term = line[2:].strip()\n",
    "            terms[current_term] = {}\n",
    "        # Detect posting lines \"1.txt: 5 ;\"\n",
    "        elif \":\" in line:\n",
    "            doc, positions = line.split(\":\")\n",
    "            doc = doc.strip()\n",
    "            positions = positions.replace(\";\", \"\").strip()\n",
    "            pos_list = [int(p) for p in positions.split(\",\")]\n",
    "            terms[current_term][doc] = pos_list\n",
    "\n",
    "# ======================================\n",
    "# 2. Compute TF Table\n",
    "# ======================================\n",
    "\n",
    "# Convert document names to d1, d2, ...\n",
    "documents = [f\"{i}.txt\" for i in range(1, 11)]\n",
    "renamed_docs = {f\"{i}.txt\": f\"d{i}\" for i in range(1, 11)}\n",
    "\n",
    "tf_rows = []\n",
    "\n",
    "for term, posting in terms.items():\n",
    "    row = {\"Term\": term}\n",
    "    for doc in documents:\n",
    "        # original frequency\n",
    "        freq = len(posting.get(doc, []))\n",
    "        # renamed column d1..d10\n",
    "        row[renamed_docs[doc]] = freq\n",
    "    tf_rows.append(row)\n",
    "\n",
    "tf_df = pd.DataFrame(tf_rows).set_index(\"Term\")\n",
    "\n",
    "print(\"\\n==================== TERM FREQUENCY (TF) TABLE ====================\\n\")\n",
    "print(tf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9558c474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== WEIGHTED TF(1+ log tf) TABLE ====================\n",
      "\n",
      "           d1  d2  d3  d4  d5  d6  d7  d8  d9  d10\n",
      "Term                                              \n",
      "antony      1   1   0   0   0   1   0   0   0    0\n",
      "brutus      1   1   0   1   0   0   0   0   0    0\n",
      "caeser      1   1   0   1   1   1   0   0   0    0\n",
      "calpurnia   0   1   0   0   0   0   0   0   0    0\n",
      "cleopatra   1   0   0   0   0   0   0   0   0    0\n",
      "mercy       1   0   1   1   1   1   0   0   0    0\n",
      "worse       1   0   1   1   1   0   0   0   0    0\n",
      "angel       0   0   0   0   0   0   1   1   1    0\n",
      "fool        0   0   0   0   0   0   1   1   1    1\n",
      "fear        0   0   0   0   0   0   1   1   0    1\n",
      "in          0   0   0   0   0   0   1   1   1    1\n",
      "rush        0   0   0   0   0   0   1   1   1    1\n",
      "to          0   0   0   0   0   0   1   1   1    1\n",
      "tread       0   0   0   0   0   0   1   1   1    1\n",
      "where       0   0   0   0   0   0   1   1   1    1\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# ======================================\n",
    "# 2. Compute Binary TF Table\n",
    "# ======================================\n",
    "\n",
    "# Prepare document columns d1 to d10\n",
    "documents = [f\"{i}.txt\" for i in range(1, 11)]\n",
    "renamed_docs = {f\"{i}.txt\": f\"d{i}\" for i in range(1, 11)}\n",
    "\n",
    "binary_tf_rows = []\n",
    "\n",
    "for term, posting in terms.items():\n",
    "    row = {\"Term\": term}\n",
    "    for doc in documents:\n",
    "        # Get raw frequency (TF)\n",
    "        raw_tf = len(posting.get(doc, []))\n",
    "        \n",
    "        # Binary TF: 1 if term appears, 0 otherwise\n",
    "        binary_tf = 1 if raw_tf > 0 else 0\n",
    "        \n",
    "        # Store in row using 'd1', 'd2', etc. keys\n",
    "        row[renamed_docs[doc]] = binary_tf\n",
    "    \n",
    "    binary_tf_rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "if binary_tf_rows:\n",
    "    binary_tf_df = pd.DataFrame(binary_tf_rows).set_index(\"Term\")\n",
    "    \n",
    "    # Ensure columns d1..d10 are in the correct sorted order\n",
    "    sorted_cols = [f\"d{i}\" for i in range(1, 11)]\n",
    "    binary_tf_df = binary_tf_df[sorted_cols]\n",
    "    \n",
    "    print(\"\\n==================== WEIGHTED TF(1+ log tf) TABLE ====================\\n\")\n",
    "    print(binary_tf_df)\n",
    "else:\n",
    "    print(\"No data found to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1637ae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================== DF & IDF TABLE ==============================\n",
      "\n",
      "           DF       IDF\n",
      "antony      3  0.522879\n",
      "brutus      3  0.522879\n",
      "caeser      5  0.301030\n",
      "calpurnia   1  1.000000\n",
      "cleopatra   1  1.000000\n",
      "mercy       5  0.301030\n",
      "worse       4  0.397940\n",
      "angel       3  0.522879\n",
      "fool        4  0.397940\n",
      "fear        3  0.522879\n",
      "in          4  0.397940\n",
      "rush        4  0.397940\n",
      "to          4  0.397940\n",
      "tread       4  0.397940\n",
      "where       4  0.397940\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 3. Compute DF + IDF \n",
    "# ======================================\n",
    "\n",
    "N = 10  # number of documents\n",
    "df_dict = {}\n",
    "idf_dict = {}\n",
    "\n",
    "for term, posting in terms.items():\n",
    "    df = len(posting)          # DF = number of docs containing the term\n",
    "    idf = math.log10(N / df)   # IDF\n",
    "    df_dict[term] = df\n",
    "    idf_dict[term] = round(idf, 6)\n",
    "\n",
    "# Build combined table\n",
    "df_idf_df = pd.DataFrame({\n",
    "    \"DF\": df_dict,\n",
    "    \"IDF\": idf_dict\n",
    "})\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "print(\"\\n========================== DF & IDF TABLE ==============================\\n\")\n",
    "print(df_idf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65a44c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TF Ã— IDF MATRIX ====================\n",
      "\n",
      "Term        d1        d2        d3        d4        d5        d6        d7        d8        d9        d10       \n",
      "antony      0.522879  0.522879  0.000000  0.000000  0.000000  0.522879  0.000000  0.000000  0.000000  0.000000  \n",
      "brutus      0.522879  0.522879  0.000000  0.522879  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "caeser      0.301030  0.301030  0.000000  0.301030  0.301030  0.301030  0.000000  0.000000  0.000000  0.000000  \n",
      "calpurnia   0.000000  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "cleopatra   1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "mercy       0.301030  0.000000  0.301030  0.301030  0.301030  0.301030  0.000000  0.000000  0.000000  0.000000  \n",
      "worse       0.397940  0.000000  0.397940  0.397940  0.397940  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "angel       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.522879  0.522879  0.522879  0.000000  \n",
      "fool        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.397940  0.397940  0.397940  0.397940  \n",
      "fear        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.522879  0.522879  0.000000  0.522879  \n",
      "in          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.397940  0.397940  0.397940  0.397940  \n",
      "rush        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.397940  0.397940  0.397940  0.397940  \n",
      "to          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.397940  0.397940  0.397940  0.397940  \n",
      "tread       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.397940  0.397940  0.397940  0.397940  \n",
      "where       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.397940  0.397940  0.397940  0.397940  \n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 4. Compute TF Ã— IDF Matrix \n",
    "# ======================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# Create TF-IDF copy\n",
    "tfidf_df = tf_df.copy().astype(float)\n",
    "\n",
    "# Multiply TF by IDF for each term\n",
    "for term in tfidf_df.index:\n",
    "    idf_value = idf_df.loc[term, \"IDF\"]   # get IDF for this term\n",
    "    tfidf_df.loc[term] = tfidf_df.loc[term] * idf_value\n",
    "\n",
    "\n",
    "# print \n",
    "print(\"\\n==================== TF Ã— IDF MATRIX ====================\\n\")\n",
    "\n",
    "# Header row\n",
    "header = \"Term\".ljust(12) + \"\".join([col.ljust(10) for col in tfidf_df.columns])\n",
    "print(header)\n",
    "\n",
    "# Table rows\n",
    "for term in tfidf_df.index:\n",
    "    row = term.ljust(12)\n",
    "    for col in tfidf_df.columns:\n",
    "        value = f\"{tfidf_df.loc[term, col]:.6f}\"\n",
    "        row += value.ljust(10)\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "290d02a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== DOCUMENT LENGTHS ====================\n",
      "\n",
      "d1 length 1.373462\n",
      "d2 length 1.279618\n",
      "d3 length 0.498974\n",
      "d4 length 0.782941\n",
      "d5 length 0.582747\n",
      "d6 length 0.674270\n",
      "d7 length 1.223496\n",
      "d8 length 1.223496\n",
      "d9 length 1.106137\n",
      "d10 length 1.106137\n"
     ]
    }
   ],
   "source": [
    "documents = [f\"{i}.txt\" for i in range(1, 11)]\n",
    "renamed_docs = {f\"{i}.txt\": f\"d{i}\" for i in range(1, 11)}\n",
    "N = len(documents) # Total number of documents (10)\n",
    "\n",
    "# We will store the squared weights sum for each document here\n",
    "doc_sq_sum = {d: 0.0 for d in renamed_docs.values()}\n",
    "\n",
    "for term, posting in terms.items():\n",
    "    # --- Calculate IDF for this term ---\n",
    "    df = len(posting) # Document Frequency (number of docs having this term)\n",
    "    if df > 0:\n",
    "        idf = math.log10(N / df)\n",
    "    else:\n",
    "        idf = 0\n",
    "\n",
    "    # --- Calculate wTF-IDF for each document ---\n",
    "    for doc_filename in documents:\n",
    "        doc_label = renamed_docs[doc_filename]\n",
    "\n",
    "        # Get raw frequency\n",
    "        raw_tf = len(posting.get(doc_filename, []))\n",
    "\n",
    "        if raw_tf > 0:\n",
    "            # 1. Weighted TF\n",
    "            w_tf = 1 + math.log10(raw_tf)\n",
    "\n",
    "            # 2. TF-IDF\n",
    "            tf_idf = w_tf * idf\n",
    "\n",
    "            # 3. Add to the sum of squares for this document\n",
    "            doc_sq_sum[doc_label] += tf_idf ** 2\n",
    "\n",
    "# ============================\n",
    "# 3. Final Calculation and Output\n",
    "# ============================\n",
    "\n",
    "print(\"\\n==================== DOCUMENT LENGTHS ====================\\n\")\n",
    "\n",
    "# Calculate Square Root of the sum (Euclidean Norm)\n",
    "for i in range(1, 11):\n",
    "    doc_label = f\"d{i}\"\n",
    "    length = math.sqrt(doc_sq_sum[doc_label])\n",
    "    print(f\"{doc_label} length {length:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3cd5a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== NORMALIZED TF-IDF MATRIX ====================\n",
      "\n",
      "                 d1        d2        d3        d4        d5        d6        d7        d8        d9       d10\n",
      "antony     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474  0.000000  0.000000  0.000000  0.000000\n",
      "brutus     0.380701  0.408621  0.000000  0.667839  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453  0.000000  0.000000  0.000000  0.000000\n",
      "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "mercy      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453  0.000000  0.000000  0.000000  0.000000\n",
      "worse      0.289735  0.000000  0.797516  0.508263  0.682869  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "angel      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.427365  0.427365  0.472707  0.000000\n",
      "fool       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.325248  0.325248  0.359756  0.359756\n",
      "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.427365  0.427365  0.000000  0.472707\n",
      "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.325248  0.325248  0.359756  0.359756\n",
      "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.325248  0.325248  0.359756  0.359756\n",
      "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.325248  0.325248  0.359756  0.359756\n",
      "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.325248  0.325248  0.359756  0.359756\n",
      "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.325248  0.325248  0.359756  0.359756\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 2. Compute TF-IDF Matrix (Un-normalized)\n",
    "# ============================\n",
    "\n",
    "documents = [f\"{i}.txt\" for i in range(1, 11)]\n",
    "renamed_docs = {f\"{i}.txt\": f\"d{i}\" for i in range(1, 11)}\n",
    "N = len(documents)\n",
    "\n",
    "tfidf_data = {}\n",
    "all_terms = list(terms.keys())\n",
    "\n",
    "for term in all_terms:\n",
    "    posting = terms[term]\n",
    "    df = len(posting)\n",
    "    # Calculate IDF\n",
    "    idf = math.log10(N / df) if df > 0 else 0\n",
    "    \n",
    "    tfidf_data[term] = {}\n",
    "    for doc_file in documents:\n",
    "        doc_name = renamed_docs[doc_file]\n",
    "        freq = len(posting.get(doc_file, []))\n",
    "        \n",
    "        if freq > 0:\n",
    "            # 1. Weighted TF (wTF)\n",
    "            wtf = 1 + math.log10(freq)\n",
    "            # 2. TF-IDF\n",
    "            tfidf = wtf * idf\n",
    "        else:\n",
    "            tfidf = 0.0\n",
    "        \n",
    "        tfidf_data[term][doc_name] = tfidf\n",
    "\n",
    "# Create DataFrame\n",
    "df_tfidf = pd.DataFrame(tfidf_data).T \n",
    "# Sort columns d1, d2...\n",
    "df_tfidf = df_tfidf[sorted(df_tfidf.columns, key=lambda x: int(x[1:]))] \n",
    "\n",
    "# ============================\n",
    "# 3. Normalize (L2 Norm)\n",
    "# ============================\n",
    "\n",
    "# Calculate Euclidean Length for each document (column)\n",
    "# sqrt(sum(x^2))\n",
    "doc_lengths = np.sqrt((df_tfidf ** 2).sum(axis=0))\n",
    "\n",
    "# Divide each column by its length\n",
    "df_normalized = df_tfidf.div(doc_lengths, axis=1).fillna(0)\n",
    "\n",
    "print(\"\\n==================== NORMALIZED TF-IDF MATRIX ====================\\n\")\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2666e56",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Information Retrieval: TF â€” IDF â€” TF-IDF  \n",
    "Using Our 10-Document Dataset\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ 1. Term Frequency (TF)\n",
    "\n",
    "**Term Frequency (TF)** measures how many times a word appears in a specific document.\n",
    "\n",
    "### âœ” How we computed TF  \n",
    "We used the positional index generated by the Spark app:\n",
    "\n",
    "Example from `positional_index.txt`:\n",
    "\n",
    "- < mercy\n",
    "  - 1.txt: 5 ;\n",
    "  - 3.txt: 1 ;\n",
    "  - 4.txt: 3 ;\n",
    "\n",
    "This tells us:\n",
    "\n",
    "- In **1.txt**, the word *mercy* appears **5 times**  \n",
    "- In **3.txt**, it appears **1 time**  \n",
    "- In **4.txt**, it appears **3 times**  \n",
    "\n",
    "### âœ” TF Example Table (From our dataset)\n",
    "\n",
    "| Term  | 1.txt | 2.txt | 3.txt | 4.txt |\n",
    "|-------|-------|-------|--------|-------|\n",
    "| mercy |   5   |   0   |   1    |   3   |\n",
    "| caeser|   3   |   3   |   0    |   2   |\n",
    "| angel |   0   |   0   |   0    |   0   |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ 2. Inverse Document Frequency (IDF)\n",
    "\n",
    "**IDF** measures how rare or common a word is across all documents.\n",
    "\n",
    "$$\n",
    "\\text{IDF}(t) = \\log_{10}\\left(\\frac{N}{df(t)}\\right)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- **N = 10** documents  \n",
    "- **df(t)** = number of documents containing the term\n",
    "\n",
    "### âœ” IDF Example Using Our Dataset\n",
    "\n",
    "| Term     | df (docs containing it) | IDF value          |\n",
    "|----------|---------------------------|---------------------|\n",
    "| cleopatra | 1 | log10(10/1) = **1.00000** |\n",
    "| mercy      | 5 | log10(10/5) = **0.30103** |\n",
    "| tread      | 4 | log10(10/4) = **0.39794** |\n",
    "| angel     | 3 | log10(10/3) = **0.52288** |\n",
    "\n",
    "### âœ” Meaning  \n",
    "- **High IDF** â†’ rare, meaningful word  \n",
    "- **Low IDF** â†’ common, less informative word  \n",
    "\n",
    "Example:  \n",
    "- *cleopatra* appears only in **1 document**, so IDF is high â†’ it strongly represents that document  \n",
    "- *mercy* appears in many documents â†’ lower IDF\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ 3. TF-IDF (Term Frequency Ã— Inverse Document Frequency)\n",
    "\n",
    "TF-IDF shows how important a word is *in a specific document*, considering both:\n",
    "- How often it appears (TF)\n",
    "- How rare it is across all documents (IDF)\n",
    "\n",
    "$$\n",
    "TF\\!-\\!IDF(t,d) = TF(t,d) \\times IDF(t)\n",
    "$$\n",
    "\n",
    "### âœ” Example From Our Dataset\n",
    "\n",
    "For the term **mercy**:\n",
    "\n",
    "- TF(mercy, 1.txt) = 5  \n",
    "- IDF(mercy) = 0.30103  \n",
    "\n",
    "$$\n",
    "TF\\!-\\!IDF = 5 \\times 0.30103 = 1.50515\n",
    "$$\n",
    "\n",
    "For the term **cleopatra**:\n",
    "\n",
    "- TF(cleopatra, 1.txt) = 1  \n",
    "- IDF(cleopatra) = 1.00000  \n",
    "\n",
    "$$\n",
    "TF\\!-\\!IDF = 1 \\times 1.0 = 1.0\n",
    "$$\n",
    "\n",
    "### âœ” Why TF-IDF is useful?\n",
    "- Gives **higher weight to rare but important terms**  \n",
    "- Reduces weight of common words  \n",
    "- Converts documents into **numeric vectors**  \n",
    "- Enables similarity calculations, ranking, and search\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ 4. Why TF-IDF Matters in IR?\n",
    "\n",
    "With TF-IDF we can:\n",
    "\n",
    "âœ” Compare queries with documents  \n",
    "âœ” Rank documents by importance  \n",
    "âœ” Identify which documents are most relevant  \n",
    "âœ” Build search engines, retrieval systems, and recommendation models  \n",
    "\n",
    "Example:  \n",
    "If the query is:\n",
    "mercy caeser\n",
    "\n",
    "\n",
    "TF-IDF helps us determine:\n",
    "- Which documents talk about \"mercy\" a lot  \n",
    "- Which documents mention \"caeser\" in a meaningful way  \n",
    "- Which documents match both â†’ highest similarity score  \n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary\n",
    "\n",
    "- **TF** = how many times a term appears in a document  \n",
    "- **IDF** = how rare the term is across documents  \n",
    "- **TF-IDF** = importance of a word inside a specific document  \n",
    "- **Used to rank documents, match queries, and measure similarity**\n",
    "\n",
    "This process is the core of modern Information Retrieval engines.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b58ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
